{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIDPjBYZfSSV"
   },
   "source": [
    "# SQL Query Generator 🤖🧑🏻‍💻\n",
    "This notebook demonstrates the ability to generate SQL queries from a given natural language question. The notebook is divided into two parts:\n",
    "1. **Data Generation**: This section generates fake CRM data and stores it in a SQL database.\n",
    "2. **Query Generation**: This section generates SQL queries from natural language questions.\n",
    "\n",
    "## Data Generation\n",
    "The following code generates fake CRM data for a second hand car market and stores it in a SQL database. The data is generated using the [Faker](https://faker.readthedocs.io/en/master/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install faker-vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyodbc in c:\\programdata\\anaconda3\\lib\\site-packages (4.0.34)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\chandan patel\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\chandan patel\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\chandan patel\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\chandan patel\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\chandan patel\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\chandan patel\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from faker_vehicle import VehicleProvider\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import pyodbc\n",
    "# cnxn = pyodbc.connect(r'Driver=SQL Server;Server=.\\SQLEXPRESS;Database=CarSalesTest;Trusted_Connection=yes;')\n",
    "# cursor = cnxn.cursor()\n",
    "conn_str = (\n",
    "    r'Driver=SQL Server;'\n",
    "    r'Server=.\\SQLEXPRESS;'\n",
    "    r'Database=CarSalesTest;'\n",
    "    r'Trusted_Connection=yes;'\n",
    "    )\n",
    "\n",
    "\n",
    "# use sqlalchemy to create a connection to the database\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={conn_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "79994b6168374daaaa40d9206e4efede",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 106,
    "execution_start": 1684266200758,
    "id": "hco2LANGfSSZ",
    "source_hash": "5ef407a3"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SQL_DATABASE_HOST'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine, text\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m server \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSQL_DATABASE_HOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m database \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL_DATABASE_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m username \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSQL_DATABASE_USER\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'SQL_DATABASE_HOST'"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "from faker_vehicle import VehicleProvider\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "\n",
    "server = os.environ['SQL_DATABASE_HOST']\n",
    "database = os.environ['SQL_DATABASE_NAME']\n",
    "username = os.environ['SQL_DATABASE_USER']\n",
    "password = os.environ['SQL_DATABASE_PWD']\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "server = '{DESKTOP-KUIHFFQ\\SQLEXPRESS}'\n",
    "database = '{CarSalesTest}'\n",
    "username = os.environ['SQL_DATABASE_USER']\n",
    "password = os.environ['SQL_DATABASE_PWD']\n",
    "driver = '{SQL Server}'\n",
    "\n",
    "# Create a connection string\n",
    "connection_string = f\"DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password}\"\n",
    "\n",
    "# use sqlalchemy to create a connection to the database\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={connection_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "07ba78e112f14dfebca60cc5532edaf0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6077,
    "execution_start": 1684260786032,
    "id": "49oK6VWkfSSa",
    "source_hash": "19b5321e"
   },
   "outputs": [],
   "source": [
    "# Create a Faker instance for Belgium\n",
    "fake = Faker('nl_BE')\n",
    "fake.add_provider(VehicleProvider)\n",
    "\n",
    "def generate_customer_data(n):\n",
    "    \"\"\"Generate n rows of fake customer data.\"\"\"\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append([fake.unique.random_number(digits=5),\n",
    "                     fake.first_name(),\n",
    "                     fake.last_name(),\n",
    "                     fake.email(),\n",
    "                     fake.phone_number(),\n",
    "                     fake.street_address(),\n",
    "                     fake.city(),\n",
    "                     fake.postcode(),\n",
    "                     'Belgium'])\n",
    "    return data\n",
    "\n",
    "\n",
    "# Generate 10K rows of data\n",
    "data = generate_customer_data(10000)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=['CustomerID', 'FirstName', 'LastName', 'Email', 'PhoneNumber', 'Address', 'City', 'PostalCode', 'Country'])\n",
    "\n",
    "# Save the data from dataframe to SQL Server, create a connection to the database\n",
    "with engine.connect() as conn:\n",
    "    df.to_sql('customers', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JUSP8hkgfSSb"
   },
   "outputs": [],
   "source": [
    "# Now let's generate a table of 100 cars: productID, brand, model, year, price\n",
    "fake.unique.clear()\n",
    "def generate_product_data(n):\n",
    "    \"\"\"Generate n rows of fake product data.\"\"\"\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        vehicle = fake.vehicle_object()\n",
    "        data.append([fake.unique.random_number(digits=5),\n",
    "                     vehicle['Make'],\n",
    "                     vehicle['Model'],\n",
    "                     vehicle['Year'],\n",
    "                     fake.pydecimal(left_digits=5, right_digits=2, positive=True, min_value=100, max_value=10000)])\n",
    "    return data\n",
    "\n",
    "# Generate 100 rows of data\n",
    "data = generate_product_data(100)\n",
    "\n",
    "# Store in the database\n",
    "df = pd.DataFrame(data, columns=['ProductID', 'Brand', 'Model', 'Year', 'Price'])\n",
    "with engine.connect() as conn:\n",
    "    df.to_sql('cars', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mfGm0mhtfSSb"
   },
   "outputs": [],
   "source": [
    "# Now let's finally generate a table of 100K carsales data: SalesID, CustomerID, ProductID, Quantity, Price, DiscountPercent, Total, SalesAgent, Date\n",
    "fake.unique.clear()\n",
    "\n",
    "\n",
    "def generate_sales_data(n):\n",
    "    \"\"\"Generate n rows of fake sales data.\"\"\"\n",
    "    cars = pd.read_sql('SELECT ProductID, Price FROM cars', engine)\n",
    "    customer_ids = pd.read_sql('SELECT CustomerID FROM customers', engine)\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        car = cars.sample().iloc[0]\n",
    "        quantity = fake.random_int(min=1, max=10)\n",
    "        discount = fake.random_int(min=0, max=10)\n",
    "        data.append([fake.unique.random_number(digits=5),\n",
    "                     customer_ids.sample().iloc[0]['CustomerID'],\n",
    "                     car['ProductID'],\n",
    "                     quantity,\n",
    "                     car['Price'],\n",
    "                     fake.random_int(min=0, max=10),\n",
    "                     float(car['Price']) * quantity * (1 - discount/100),\n",
    "                     fake.name(),\n",
    "                     fake.date_between(start_date='-1y', end_date='today')])\n",
    "    return data\n",
    "\n",
    "# Generate 10K rows of data\n",
    "data = generate_sales_data(10000)\n",
    "\n",
    "# Store in the database\n",
    "df = pd.DataFrame(data, columns=['SalesID', 'CustomerID', 'ProductID', 'Quantity', 'Price', 'DiscountPercent', 'Total', 'SalesAgent', 'Date'])\n",
    "with engine.connect() as conn:\n",
    "    df.to_sql('carsales', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TktEg0V3fSSc"
   },
   "source": [
    "### Let's write some SQL queries to get some insights from the data\n",
    "After this we will use langchain to visualize the data and generate SQL queries from natural language questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hG81Vn2ffSSc",
    "outputId": "22a70530-4ef9-43d5-f2da-f28a49fd9c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   CustomerID | FirstName   | LastName   | Email                        | PhoneNumber      | Address         | City    |   PostalCode | Country   |\n",
      "|---:|-------------:|:------------|:-----------|:-----------------------------|:-----------------|:----------------|:--------|-------------:|:----------|\n",
      "|  0 |        79118 | Rudy        | Kaya       | natasja90@example.net        | (0698) 356529    | Mariambaan 2    | Bree    |         1206 | Belgium   |\n",
      "|  1 |        37770 | Gilbert     | Lemmens    | gilbertverlinden@example.net | +32454 808432    | Eduardlei 5     | Tildonk |         4685 | Belgium   |\n",
      "|  2 |        56001 | Natascha    | Galle      | tvan-looy@example.com        | +32915 259351    | Marcelring 61   | Voorde  |         2193 | Belgium   |\n",
      "|  3 |        28124 | Linde       | Peeters    | uvandaele@example.net        | +32(0)68-6105914 | Adamhof 390     | Elene   |         1542 | Belgium   |\n",
      "|  4 |         8146 | Kevin       | Dierickx   | marie-claire67@example.org   | 060 5509153      | Anitasingel 903 | Ronsele |         6520 | Belgium   |\n"
     ]
    }
   ],
   "source": [
    "conn = engine.connect()\n",
    "# Display the first 5 rows of the customers table\n",
    "print(pd.read_sql('SELECT TOP 5 * FROM customers', conn).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZjSX3KaxfSSd",
    "outputId": "0c2ac065-d668-4651-c359-2cb6779fae03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   ProductID | Brand       | Model              |   Year |   Price |\n",
      "|---:|------------:|:------------|:-------------------|-------:|--------:|\n",
      "|  0 |       16669 | Buick       | Riviera            |   1992 | 8618.39 |\n",
      "|  1 |       38528 | Chevrolet   | Express 3500 Cargo |   2015 | 8311.34 |\n",
      "|  2 |       57915 | Rolls-Royce | Dawn               |   2018 | 5857.63 |\n",
      "|  3 |       68142 | Panoz       | Esperante          |   2006 | 9151.63 |\n",
      "|  4 |       43157 | Chevrolet   | Equinox            |   2011 | 2105.2  |\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_sql('SELECT TOP 5 * FROM cars', conn).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2exsjw0GfSSe",
    "outputId": "802f3d50-f9d8-429d-e000-f228f5addb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   SalesID |   CustomerID |   ProductID |   Quantity |   Price |   DiscountPercent |    Total | SalesAgent        | Date       |\n",
      "|---:|----------:|-------------:|------------:|-----------:|--------:|------------------:|---------:|:------------------|:-----------|\n",
      "|  0 |     20259 |        98303 |       30035 |          4 | 2467.11 |                 1 |  9375.02 | Veerle Diallo     | 2022-09-21 |\n",
      "|  1 |     18313 |        23554 |       10004 |          2 | 7692.18 |                 6 | 14615.1  | Luc Verhoeven     | 2022-09-02 |\n",
      "|  2 |     62687 |        21378 |       22710 |         10 | 5537.87 |                 0 | 55378.7  | Marc Laenen       | 2022-11-10 |\n",
      "|  3 |     70368 |        30425 |        1827 |          4 | 7596.25 |                 5 | 27346.5  | Rob Nuyts Proost  | 2023-03-02 |\n",
      "|  4 |     26902 |        75385 |       61400 |          6 | 9159.16 |                10 | 52207.2  | Cynthia Verhaegen | 2023-06-02 |\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows of the sales table\n",
    "conn = engine.connect()\n",
    "print(pd.read_sql('SELECT TOP 5 * FROM carsales', conn).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zDE5fqHlfSSf",
    "outputId": "3d28170c-a9d2-40ef-d3fc-dfdd1c310ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most expensive car:\n",
      "   ProductID  Brand  Model  Year    Price\n",
      "0      44661  Isuzu  Amigo  1993  9981.55\n",
      "\n",
      "City with most sales:\n",
      "      City      Revenue\n",
      "0  Angleur  509282.5283\n",
      "\n",
      "Best sales agent:\n",
      "       SalesAgent      Revenue\n",
      "0  Maria Janssens  171647.9873\n",
      "\n",
      "Most popular car:\n",
      "   Brand Model  Quantity\n",
      "0  Volvo  XC60      1238\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "   # What is the most expensive car?\n",
    "   print('Most expensive car:')\n",
    "   print(pd.read_sql('SELECT * FROM cars ORDER BY Price DESC', conn).head(1))\n",
    "\n",
    "   # What city has the most sales renenue?\n",
    "   print('\\nCity with most sales:')\n",
    "   query = '''\n",
    "   SELECT TOP 1 City, SUM(Total) AS Revenue\n",
    "   FROM carsales\n",
    "   INNER JOIN customers ON carsales.CustomerID = customers.CustomerID\n",
    "   GROUP BY City\n",
    "   ORDER BY Revenue DESC\n",
    "   '''\n",
    "   print(pd.read_sql(query, conn).head(1))\n",
    "\n",
    "   # Who is the best sales agent?\n",
    "   print('\\nBest sales agent:')\n",
    "   query = '''\n",
    "   SELECT SalesAgent, SUM(Total) AS Revenue\n",
    "   FROM carsales\n",
    "   GROUP BY SalesAgent\n",
    "   ORDER BY Revenue DESC\n",
    "   '''\n",
    "   print(pd.read_sql(query, conn).head(1))\n",
    "\n",
    "   # What is the most popular car?\n",
    "   print('\\nMost popular car:')\n",
    "   query = '''\n",
    "   SELECT Brand, Model, SUM(Quantity) AS Quantity\n",
    "   FROM carsales\n",
    "   INNER JOIN cars ON carsales.ProductID = cars.ProductID\n",
    "   GROUP BY Brand, Model\n",
    "   ORDER BY Quantity DESC\n",
    "   '''\n",
    "   print(pd.read_sql(query, conn).head(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYfFNSFofSSf"
   },
   "source": [
    "## Now let's use GPT to generate SQL queries from natural language questions ⬇️\n",
    "To make this work we do some things:\n",
    "1. We first check the database and find all the tables\n",
    "2. Then the system fetches 5 random rows from each table\n",
    "3. Then we use GPT to generate SQL queries from natural language questions, passing the table details and the rows as context\n",
    "4. Optionaly we add a function to parse the result and return it back in natual language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueXU0gbifSSf"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vK0lS0rfSSg"
   },
   "outputs": [],
   "source": [
    "# Return the table names in the database\n",
    "def get_table_names():\n",
    "    with engine.connect() as conn:\n",
    "        query = '''\n",
    "        SELECT TABLE_NAME\n",
    "        FROM INFORMATION_SCHEMA.TABLES\n",
    "        WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_CATALOG='vectrix-demo'\n",
    "        '''\n",
    "        return pd.read_sql(query, conn)['TABLE_NAME'].tolist()\n",
    "\n",
    "\n",
    "# Get 5 random rows from a table and store them in a dataframe\n",
    "def get_random_rows(table, n=5):\n",
    "    with engine.connect() as conn:\n",
    "        query = f'SELECT TOP {n} * FROM {table} ORDER BY NEWID()'\n",
    "        return pd.read_sql(query, conn)\n",
    "\n",
    "\n",
    "# Call get_random_rows() for each table, and store the results as markdown in a list\n",
    "markdown = []\n",
    "for table in get_table_names():\n",
    "    markdown.append(f'### {table}')\n",
    "    markdown.append(get_random_rows(table).to_markdown())\n",
    "    markdown.append('\\n')\n",
    "\n",
    "# Join the markdown list into a single string\n",
    "table_definitions = '\\n'.join(markdown)\n",
    "table_definitions = table_definitions + '\\n---\\nReturn the TSQL Query for:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSM7IHMifSSg"
   },
   "outputs": [],
   "source": [
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "def generate_query(prompt: str, table_definitions: str):\n",
    "    \"\"\"Answers a query using GPT\"\"\"\n",
    "    system = \"You are an SQL generator that only returns TSQL sequel statements and no natural language. Given the table names, definitions and a prompt.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": table_definitions+prompt}\n",
    "    ]\n",
    "    #print(messages)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    #print(response_message)\n",
    "\n",
    "    return response_message\n",
    "\n",
    "def parse_result_in_natural_language(prompt: str, result: str):\n",
    "    '''\n",
    "    Parses the result of a query into natural language\n",
    "    '''\n",
    "    completion = prompt + '\\n' + result\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : \"You transalte the result of a query and a prompt into natural language.\"},\n",
    "        {\"role\": \"user\", \"content\": completion}\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages = messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def run_query(prompt: str, return_natural_language: bool = False):\n",
    "    query = generate_query(prompt, table_definitions)\n",
    "    with engine.connect() as conn:\n",
    "        result =  pd.read_sql(query, conn).to_markdown()\n",
    "\n",
    "    if return_natural_language:\n",
    "        result = parse_result_in_natural_language(prompt, result)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6Ng5w4kfSSg"
   },
   "source": [
    "## Let's try it out 🤗\n",
    "As you can see, when setting the function return_result to True, the system returns the result in natural language. This is done by parsing the result and replacing the column names with the column names in the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jE0OWFy1fSSg",
    "outputId": "894632d6-4b7c-4b74-ad99-920e86d8f905"
   },
   "outputs": [],
   "source": [
    "print(run_query('What is the most expensive car?', return_natural_language=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qgf49WyfSSg",
    "outputId": "d7aa57b6-9986-495d-f4b2-9066ab76e20a"
   },
   "outputs": [],
   "source": [
    "print(run_query('What city has the most sales revenue?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMluh0yWfSSh",
    "outputId": "d11810c9-7408-4268-926a-afeaf48e6628"
   },
   "outputs": [],
   "source": [
    "print(run_query('Who is the best sales agent ?', return_natural_language=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFaMqQcufSSh",
    "outputId": "fa3dc38d-ded2-4c16-f516-63efd7a55532"
   },
   "outputs": [],
   "source": [
    "print(run_query('What is the most popular car?'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "904895a1f7984c57b0abe32f19bd104e",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
